# -*- coding: utf-8 -*-
"""Churn ML predictive telco - Aug 2025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t4mWPuxBCUqTkBRTkxh0NemlDSyWzXxc
"""

code snippet 1
#installing pycaret package for ML model prediction
!pip install git+https://github.com/pycaret/pycaret.git

#code snippet 2
#inserting data from the url to initiate ML algorithm
import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/Imjuandiaz/churn-data/refs/heads/main/WA_Fn-UseC_-Telco-Customer-Churn.csv")

df

#Code snippet 3
#displaying columns
df.columns

#code snippet 4
#setting up the classification pycaret ML model
from pycaret.classification import *

# Code snippet 5
# Setting the target variable
y = 'Churn'

# Code snippet 6
# Setting the ignored variables(noise variables, redundant variables,  variables that are missing more than 20% data etc)
ignored_cols = ['customerID','gender','MonthlyCharges', 'TotalCharges', 'PhoneService', 'MultipleLines']

# Code snippet 7
# Setting the numerical variables
num_cols = ['SeniorCitizen', 'tenure']

# Code snippet 8
# Setting the categorical variables
cat_cols = [ 'Partner', 'Dependents',
        'InternetService',
       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',
       'PaymentMethod' ]

# Code snippet 9
# Setting up/configuring the pycaret setup for Classification ML modeling
classification_setup = setup(df,
                        target = y,
                        ignore_features = ignored_cols,
                        categorical_features = cat_cols,
                        numeric_features = num_cols, train_size = 0.7)

#code snippet 10
# Running pycaret to invoke ML algorithms
compare_models()

# Code snippet 11
# Building the model with the best algorithm
best_model = create_model('ada')

# 7. Visualizar métr,icas individuales
plot_model(best_model, plot = 'auc')          # Curva AUC-ROC
plot_model(best_model, plot = 'confusion_matrix')  # Matriz de confusión

# Code snippet 12
# Predicting 'eBook Subscriber Flag' on a dataset
predictions = predict_model(best_model, df)

# Precision-Recall
plot_model(best_model, plot = 'pr')

# Code snippet 13
# Exporting predictions to a csv file
predictions.to_csv('ada Churn predictions.csv')

# Curva de aprendizaje
plot_model(best_model, plot = 'learning')

#code snippet 14
#inserting data from the url to initiate prediction process
import pandas as pd

client_data = pd.read_csv("https://raw.githubusercontent.com/Imjuandiaz/churn-data/refs/heads/main/WA_Fn-UseC_-Telco-Customer-Churn.csv")

client_data

# Code snippet 15
# Predicting 'eBook Subscriber Flag' for the client dataset
client_predictions = predict_model(best_model, client_data)

# Frontera de decisión (2D)
plot_model(best_model, plot = 'boundary')

# Code snippet 16
# Predicting 'eBook Subscriber Flag' for the client dataset
client_predictions = predict_model(best_model, client_data)


# Renaming label as Predicted 'eBook Subscriber Flag' and rounding it to 2 decimals
client_predictions = client_predictions.rename(columns = {'Label':'Churn prediction'}).round(2)


# Exporting 'eBook Subscriber Flag' predictions to a csv file
client_predictions.to_csv('Final ADA Churn Prediction.csv')

# Importancia de variable
plot_model(best_model, plot = 'feature')

#code snippet 17
# getting the parameter for the Regression ML model
best_model_params = best_model.get_params()

#code snippet 18
#Print the Diccionary of Parameters
import pprint
pprint.pprint(best_model_params)

"""## Load the data

### Subtask:
Load the dataset from the provided URL into a pandas DataFrame.

**Reasoning**:
Load the dataset from the provided URL into a pandas DataFrame.
"""

df = pd.read_csv("https://raw.githubusercontent.com/Imjuandiaz/churn-data/refs/heads/main/WA_Fn-UseC_-Telco-Customer-Churn.csv")

# Setting the ignored variables(noise variables, redundant variables,  variables that are missing more than 20% data etc)
ignored_cols = ['customerID','gender','MonthlyCharges', 'TotalCharges', 'PhoneService', 'MultipleLines']

# Setting the numerical variables
num_cols = ['SeniorCitizen', 'tenure']

# Setting the categorical variables
cat_cols = [ 'Partner', 'Dependents',
        'InternetService',
       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',
       'PaymentMethod' ]

X = df.drop('Churn', axis=1)
y = df['Churn']

X_categorical = X[cat_cols]
X_numerical = X[num_cols]

X_categorical_encoded = pd.get_dummies(X_categorical, columns=cat_cols, drop_first=True)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_numerical_scaled = scaler.fit_transform(X_numerical)
X_numerical_scaled = pd.DataFrame(X_numerical_scaled, columns=num_cols, index=X_numerical.index)

X_processed = pd.concat([X_numerical_scaled, X_categorical_encoded], axis=1)

"""**Reasoning**:
Split the preprocessed data and target variable into training and testing sets.


"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)

"""## Define features and target

### Subtask:
Define features and target

**Reasoning**:
Train a Logistic Regression model using the training data.
"""

from sklearn.linear_model import LogisticRegression

logistic_regression_model = LogisticRegression()
logistic_regression_model.fit(X_train, y_train)

"""**Reasoning**:
Import the necessary metrics and evaluate the model using accuracy, precision, recall, and F1-score.


"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

y_pred = logistic_regression_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='Yes')
recall = recall_score(y_test, y_pred, pos_label='Yes')
f1 = f1_score(y_test, y_pred, pos_label='Yes')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification # For a dummy dataset

# Assuming X, y are already loaded. If not, here's a dummy example:
X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)
y = ['Yes' if val == 1 else 'No' for val in y] # Convert to 'Yes'/'No' for example

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Assuming logistic_regression_model is already trained. If not, here's an example:
logistic_regression_model = LogisticRegression(random_state=42, solver='liblinear')
logistic_regression_model.fit(X_train, y_train)

y_pred = logistic_regression_model.predict(X_test)
y_proba = logistic_regression_model.predict_proba(X_test)[:, 1] # Probability of the positive class ('Yes')

# --- Calculate and Print Metrics ---
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='Yes')
recall = recall_score(y_test, y_pred, pos_label='Yes')
f1 = f1_score(y_test, y_pred, pos_label='Yes')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")

# --- 1. Export Predictions to CSV ---
predictions_df = pd.DataFrame({
    'Actual_Class': y_test,
    'Predicted_Class': y_pred
})

# You can add the probabilities if desired
# predictions_df['Predicted_Probability_Yes'] = y_proba

predictions_csv_path = 'model_predictions.csv'
predictions_df.to_csv(predictions_csv_path, index=False)
print(f"\nPredictions exported to {predictions_csv_path}")

# --- 2. Create Visualizations of Metrics ---

# a) Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=['No', 'Yes'])
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted No', 'Predicted Yes'], yticklabels=['Actual No', 'Actual Yes'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# b) Bar Chart of Key Metrics
metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
metrics_values = [accuracy, precision, recall, f1]

plt.figure(figsize=(10, 6))
sns.barplot(x=metrics_names, y=metrics_values, palette='viridis')
plt.ylim(0, 1) # Metrics are between 0 and 1
plt.title('Model Performance Metrics')
plt.ylabel('Score')
for index, value in enumerate(metrics_values):
    plt.text(index, value + 0.02, f'{value:.2f}', ha='center')
plt.show()

# c) ROC Curve (for binary classification)
# Need numerical labels for roc_curve
y_test_numeric = [1 if val == 'Yes' else 0 for val in y_test]
fpr, tpr, thresholds = roc_curve(y_test_numeric, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()